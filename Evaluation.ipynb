{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Levenshtein import distance as lev_distance\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read nid data original and predicted\n",
    "df_original_nid=pd.read_csv(\"national_id/high_resolution_final_ids.csv\")\n",
    "df_predicted_nid=pd.read_csv(\"national_id/high_resolution_National_IDs_predicted.csv\")\n",
    "\n",
    "\n",
    "# read credit card data original and predicted\n",
    "df_original_credit=pd.read_csv(\"credit_card/cards200V2.csv\")\n",
    "df_predicted_credit=pd.read_csv(\"credit_card/ocr_result_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standarize column names in original and predicted\n",
    "df_predicted_nid.rename(columns={\"FN\":\"First Name\",\"LN\":\"Last Name\",\"Add1\":\"Address\",\"Add2\":\"District-Govrnate\",\"Id\":\"National ID\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>District-Govrnate</th>\n",
       "      <th>National ID</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-ايمن</td>\n",
       "      <td>أحمذ محمد سيد</td>\n",
       "      <td>ع 586 نثر مصر القرئقل</td>\n",
       "      <td>التجمع الاول. - القاهرة.</td>\n",
       "      <td>238610962102906</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image1.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>محمد</td>\n",
       "      <td>عبد المئعم محمد السيد</td>\n",
       "      <td>عزبة المهاجرين</td>\n",
       "      <td>المنتزه .- الاسكندرية</td>\n",
       "      <td>27010200202071</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image2.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>عيد</td>\n",
       "      <td>سعيد سلامة الحمادين</td>\n",
       "      <td>حى الحمادين</td>\n",
       "      <td>الشيغ زويد - شمال سيناء</td>\n",
       "      <td>24308233400071</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image3.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>احمد</td>\n",
       "      <td>خالد محمد على</td>\n",
       "      <td>كلا حين ابنود</td>\n",
       "      <td>مركز قنا - قنا</td>\n",
       "      <td>29010102701652</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image4.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>فاطمه</td>\n",
       "      <td>NaN</td>\n",
       "      <td>\"ش مسجدالرحمه-فيكتوريا</td>\n",
       "      <td>اول المنتزه .- الاسكندرية</td>\n",
       "      <td>29303210200586</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>محمد</td>\n",
       "      <td>نهاد محمد صديق الشوربجى</td>\n",
       "      <td>عمارة /ا١‏ مساكن الصباط</td>\n",
       "      <td>اول السلام - القاهره</td>\n",
       "      <td>29602060101417</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image6.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>علياء</td>\n",
       "      <td>محمؤود احمد نصر شلبى</td>\n",
       "      <td>6 عبدالوهاب زيدان-ميدان فيكتوريا</td>\n",
       "      <td>الساحل - القاهره</td>\n",
       "      <td>29701050101841</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image7.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>احمد</td>\n",
       "      <td>حسين عواض حسن شاهين</td>\n",
       "      <td>نهاية وابور الفولى من بن واصل</td>\n",
       "      <td>ثان الرمل - الاسكندرية</td>\n",
       "      <td>29204180200995</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image8.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>محمود</td>\n",
       "      <td>عصام عبدالعزيز قطب محمد</td>\n",
       "      <td>عبدالقادر - الحكماء</td>\n",
       "      <td>الزقازيق ثان - الشرقية</td>\n",
       "      <td>28909091300595</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image9.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>احمد</td>\n",
       "      <td>منير شوكت احمد</td>\n",
       "      <td>NaN</td>\n",
       "      <td>مركز بنها - القليوبية</td>\n",
       "      <td>29006141400948</td>\n",
       "      <td>/content/drive/MyDrive/NID_Data/image10.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  First Name                Last Name                           Address  \\\n",
       "0      -ايمن            أحمذ محمد سيد             ع 586 نثر مصر القرئقل   \n",
       "1       محمد    عبد المئعم محمد السيد                    عزبة المهاجرين   \n",
       "2        عيد      سعيد سلامة الحمادين                       حى الحمادين   \n",
       "3       احمد            خالد محمد على                     كلا حين ابنود   \n",
       "4      فاطمه                      NaN            \"ش مسجدالرحمه-فيكتوريا   \n",
       "5       محمد  نهاد محمد صديق الشوربجى           عمارة /ا١‏ مساكن الصباط   \n",
       "6      علياء     محمؤود احمد نصر شلبى  6 عبدالوهاب زيدان-ميدان فيكتوريا   \n",
       "7       احمد      حسين عواض حسن شاهين     نهاية وابور الفولى من بن واصل   \n",
       "8      محمود  عصام عبدالعزيز قطب محمد               عبدالقادر - الحكماء   \n",
       "9       احمد           منير شوكت احمد                               NaN   \n",
       "\n",
       "           District-Govrnate      National ID  \\\n",
       "0   التجمع الاول. - القاهرة.  238610962102906   \n",
       "1      المنتزه .- الاسكندرية   27010200202071   \n",
       "2    الشيغ زويد - شمال سيناء   24308233400071   \n",
       "3             مركز قنا - قنا   29010102701652   \n",
       "4  اول المنتزه .- الاسكندرية   29303210200586   \n",
       "5       اول السلام - القاهره   29602060101417   \n",
       "6           الساحل - القاهره   29701050101841   \n",
       "7     ثان الرمل - الاسكندرية   29204180200995   \n",
       "8     الزقازيق ثان - الشرقية   28909091300595   \n",
       "9      مركز بنها - القليوبية   29006141400948   \n",
       "\n",
       "                                    image_path  \n",
       "0   /content/drive/MyDrive/NID_Data/image1.jpg  \n",
       "1   /content/drive/MyDrive/NID_Data/image2.jpg  \n",
       "2   /content/drive/MyDrive/NID_Data/image3.jpg  \n",
       "3   /content/drive/MyDrive/NID_Data/image4.jpg  \n",
       "4   /content/drive/MyDrive/NID_Data/image5.jpg  \n",
       "5   /content/drive/MyDrive/NID_Data/image6.jpg  \n",
       "6   /content/drive/MyDrive/NID_Data/image7.jpg  \n",
       "7   /content/drive/MyDrive/NID_Data/image8.jpg  \n",
       "8   /content/drive/MyDrive/NID_Data/image9.jpg  \n",
       "9  /content/drive/MyDrive/NID_Data/image10.jpg  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_predicted_nid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Address</th>\n",
       "      <th>District-Govrnate</th>\n",
       "      <th>National ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Image1</td>\n",
       "      <td>ايمن</td>\n",
       "      <td>احمد محمد سيد</td>\n",
       "      <td>ع ٣٨٤ دار مصر القرنفل</td>\n",
       "      <td>التجمع الاول-القاهره</td>\n",
       "      <td>28610162102956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>image2</td>\n",
       "      <td>محمد</td>\n",
       "      <td>عبدالمنعم محمد السيد</td>\n",
       "      <td>عزبه المهاجرين</td>\n",
       "      <td>المنتزه- الاسكندريه</td>\n",
       "      <td>27010200202071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>image3</td>\n",
       "      <td>عيد</td>\n",
       "      <td>سعيد سلامه الحمادين</td>\n",
       "      <td>حي الحمادين</td>\n",
       "      <td>الشيخ زويد - شمال سيناء</td>\n",
       "      <td>24308233400071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>image4</td>\n",
       "      <td>احمد</td>\n",
       "      <td>خالد محمد على</td>\n",
       "      <td>كلا حين ابنود</td>\n",
       "      <td>مركز قنا- قنا</td>\n",
       "      <td>29010102701652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>image5</td>\n",
       "      <td>فاطمه</td>\n",
       "      <td>خليل حسن خليل محمد</td>\n",
       "      <td>٢ ش مسجد الرحمه-فيكتوريا</td>\n",
       "      <td>اول المنتزه - الاسكندرية</td>\n",
       "      <td>29203210200586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>image6</td>\n",
       "      <td>محمد</td>\n",
       "      <td>نهاد محمد صدقي الشوربجي</td>\n",
       "      <td>عمارة ١٧ مساكن الضباط</td>\n",
       "      <td>اول السلام - القاهره</td>\n",
       "      <td>29202060101417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>image7</td>\n",
       "      <td>علياء</td>\n",
       "      <td>محمود احمد نصر شلبي</td>\n",
       "      <td>٢٨ عبدالوهاب زيدان-ميدان فيكتوريا</td>\n",
       "      <td>الساحل- القاهره</td>\n",
       "      <td>29701050101841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Image8</td>\n",
       "      <td>احمد</td>\n",
       "      <td>حسين عواض حسن شاهين</td>\n",
       "      <td>نهاية وابور الفولى من بن واصل</td>\n",
       "      <td>ثان الرمل - الاسكندرية</td>\n",
       "      <td>29204180200995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>image9</td>\n",
       "      <td>محمود</td>\n",
       "      <td>عصام عبد العزيز قطب محمد</td>\n",
       "      <td>٩ ش عبد القادر - الحكماء</td>\n",
       "      <td>الزقازيق ثان الشرقية</td>\n",
       "      <td>28909091300595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>image10</td>\n",
       "      <td>احمد</td>\n",
       "      <td>منير شوكت احمد</td>\n",
       "      <td>بطا</td>\n",
       "      <td>مركز بنها - القليوبية</td>\n",
       "      <td>29006141400948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Image First Name                 Last Name  \\\n",
       "0   Image1       ايمن             احمد محمد سيد   \n",
       "1   image2       محمد      عبدالمنعم محمد السيد   \n",
       "2   image3        عيد       سعيد سلامه الحمادين   \n",
       "3   image4       احمد             خالد محمد على   \n",
       "4   image5      فاطمه        خليل حسن خليل محمد   \n",
       "5   image6       محمد   نهاد محمد صدقي الشوربجي   \n",
       "6   image7      علياء       محمود احمد نصر شلبي   \n",
       "7   Image8       احمد       حسين عواض حسن شاهين   \n",
       "8   image9      محمود  عصام عبد العزيز قطب محمد   \n",
       "9  image10       احمد            منير شوكت احمد   \n",
       "\n",
       "                             Address         District-Govrnate     National ID  \n",
       "0              ع ٣٨٤ دار مصر القرنفل      التجمع الاول-القاهره  28610162102956  \n",
       "1                     عزبه المهاجرين       المنتزه- الاسكندريه  27010200202071  \n",
       "2                        حي الحمادين   الشيخ زويد - شمال سيناء  24308233400071  \n",
       "3                      كلا حين ابنود             مركز قنا- قنا  29010102701652  \n",
       "4           ٢ ش مسجد الرحمه-فيكتوريا  اول المنتزه - الاسكندرية  29203210200586  \n",
       "5              عمارة ١٧ مساكن الضباط      اول السلام - القاهره  29202060101417  \n",
       "6  ٢٨ عبدالوهاب زيدان-ميدان فيكتوريا           الساحل- القاهره  29701050101841  \n",
       "7      نهاية وابور الفولى من بن واصل    ثان الرمل - الاسكندرية  29204180200995  \n",
       "8           ٩ ش عبد القادر - الحكماء      الزقازيق ثان الشرقية  28909091300595  \n",
       "9                                بطا     مركز بنها - القليوبية  29006141400948  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_nid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standarize path column to be primary key for both dfs \n",
    "df_original_nid['path'] = df_original_nid['Image'].apply(lambda x: f'{x}.jpg'.lower())\n",
    "df_predicted_nid['path'] = df_predicted_nid['image_path'].apply(lambda x: x.split('/')[-1].lower())\n",
    "df_predicted_nid.drop(columns=\"image_path\",inplace=True)\n",
    "df_original_nid.drop(columns=\"Image\",inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation based on 10 images\n"
     ]
    }
   ],
   "source": [
    "# make sure data are on the same order by inner merge \n",
    "inner_df=pd.merge(df_original_nid,df_predicted_nid, on=\"path\", how=\"inner\")\n",
    "print(f\"Evaluation based on {len(inner_df)} images\")\n",
    "df_original_nid_1 = inner_df[[col for col in inner_df.columns if '_x' in col] ].rename(columns=lambda x: x.replace('_x', ''))\n",
    "df_predicted_nid = inner_df[[col for col in inner_df.columns if '_y' in col] ].rename(columns=lambda x: x.replace('_y', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Metrics Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def levenshtein_distance(s1, s2):\n",
    "    return lev_distance(str(s1), str(s2))\n",
    "\n",
    "def word_error_rate(reference, hypothesis):\n",
    "    ref_words = word_tokenize(str(reference))\n",
    "    hyp_words = word_tokenize(str(hypothesis))\n",
    "    distance = lev_distance(ref_words, hyp_words)\n",
    "    return distance / len(ref_words)\n",
    "\n",
    "def character_error_rate(reference, hypothesis):\n",
    "    distance = lev_distance(str(reference), str(hypothesis))\n",
    "    return distance / len(str(reference))\n",
    "\n",
    "\n",
    "def precision_recall_f1(reference, hypothesis):\n",
    "    ref_words = set(word_tokenize(str(reference)))\n",
    "    hyp_words = set(word_tokenize(str(hypothesis)))\n",
    "    \n",
    "    true_positives = len(ref_words.intersection(hyp_words))\n",
    "    false_positives = len(hyp_words - ref_words)\n",
    "    false_negatives = len(ref_words - hyp_words)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
    "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    return precision, recall, f1\n",
    "\n",
    "def evaluate_ocr_results(extracted_df, ground_truth_df):\n",
    "    if not extracted_df.columns.equals(ground_truth_df.columns):\n",
    "        raise ValueError(\"Columns in extracted_df and ground_truth_df do not match\")\n",
    "    \n",
    "    results = {}\n",
    "    for column in extracted_df.columns:\n",
    "        column_results = {\n",
    "            'levenshtein': [],\n",
    "            'wer': [],\n",
    "            'cer': [],\n",
    "            'precision': [],\n",
    "            'recall': [],\n",
    "            'f1': []\n",
    "        }\n",
    "        \n",
    "        for ext, truth in zip(extracted_df[column], ground_truth_df[column]):\n",
    "            column_results['levenshtein'].append(levenshtein_distance(ext, truth))\n",
    "            column_results['wer'].append(word_error_rate(truth, ext))\n",
    "            column_results['cer'].append(character_error_rate(truth, ext))\n",
    "            p, r, f1 = precision_recall_f1(truth, ext)\n",
    "            column_results['precision'].append(p)\n",
    "            column_results['recall'].append(r)\n",
    "            column_results['f1'].append(f1)\n",
    "        \n",
    "        results[column] = {metric: np.mean(values) for metric, values in column_results.items()}\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results(results):\n",
    "    print(\"Evaluation Results:\")\n",
    "    for field, metrics in results.items():\n",
    "        print(f\"\\n{field}:\")\n",
    "        print(f\"  Avg Levenshtein Distance: {metrics['levenshtein']:.2f}\")\n",
    "        print(f\"  Word Error Rate: {metrics['wer']:.2%}\")\n",
    "        print(f\"  Character Error Rate: {metrics['cer']:.2%}\")\n",
    "        print(f\"  Precision: {metrics['precision']:.2%}\")\n",
    "        print(f\"  Recall: {metrics['recall']:.2%}\")\n",
    "        print(f\"  F1 Score: {metrics['f1']:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "\n",
      "First Name:\n",
      "  Avg Levenshtein Distance: 0.10\n",
      "  Word Error Rate: 10.00%\n",
      "  Character Error Rate: 2.50%\n",
      "  Precision: 90.00%\n",
      "  Recall: 90.00%\n",
      "  F1 Score: 90.00%\n",
      "\n",
      "Last Name:\n",
      "  Avg Levenshtein Distance: 2.90\n",
      "  Word Error Rate: 37.33%\n",
      "  Character Error Rate: 15.84%\n",
      "  Precision: 65.83%\n",
      "  Recall: 66.00%\n",
      "  F1 Score: 65.71%\n",
      "\n",
      "Address:\n",
      "  Avg Levenshtein Distance: 2.60\n",
      "  Word Error Rate: 47.67%\n",
      "  Character Error Rate: 20.80%\n",
      "  Precision: 56.50%\n",
      "  Recall: 52.33%\n",
      "  F1 Score: 53.80%\n",
      "\n",
      "District-Govrnate:\n",
      "  Avg Levenshtein Distance: 1.80\n",
      "  Word Error Rate: 64.50%\n",
      "  Character Error Rate: 9.18%\n",
      "  Precision: 65.00%\n",
      "  Recall: 72.17%\n",
      "  F1 Score: 67.60%\n",
      "\n",
      "National ID:\n",
      "  Avg Levenshtein Distance: 0.50\n",
      "  Word Error Rate: 30.00%\n",
      "  Character Error Rate: 3.57%\n",
      "  Precision: 70.00%\n",
      "  Recall: 70.00%\n",
      "  F1 Score: 70.00%\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_ocr_results(df_predicted_nid, df_original_nid_1)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Analysis for Arabic character position error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop national ids as its just numbers we would work on alpahpitical only\n",
    "df_original_nid_1.drop(columns=\"National ID\",inplace= True)\n",
    "df_predicted_nid.drop(columns=\"National ID\",inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Character Initial_Accuracy  Initial_Total Medial_Accuracy  Medial_Total  \\\n",
      "0          ث          100.00%              2           0.00%             0   \n",
      "1          ى            0.00%              0           0.00%             0   \n",
      "2          ت            0.00%              0         100.00%             4   \n",
      "3          ج            0.00%              0         100.00%             3   \n",
      "4          ص          100.00%              1         100.00%             4   \n",
      "5          ء            0.00%              0           0.00%             0   \n",
      "6          ح          100.00%              4          94.12%            17   \n",
      "7          و          100.00%              2          93.33%            15   \n",
      "8          م           92.86%             14          92.86%            28   \n",
      "9          ك          100.00%              1          87.50%             8   \n",
      "10         ب          100.00%              2          90.91%            11   \n",
      "11         س          100.00%              4          77.78%             9   \n",
      "12         ل            0.00%              0          82.05%            39   \n",
      "13         ن          100.00%              3          71.43%            14   \n",
      "14         ة            0.00%              0           0.00%             0   \n",
      "15         ا           80.00%             35          84.62%            39   \n",
      "16         ز          100.00%              2          83.33%             6   \n",
      "17         ع           90.91%             11          33.33%             3   \n",
      "18         د            0.00%              1          90.00%            10   \n",
      "19         ر            0.00%              0          73.33%            15   \n",
      "20         ف          100.00%              2          50.00%             2   \n",
      "21         ي            0.00%              0          82.76%            29   \n",
      "22         ش          100.00%              4          66.67%             3   \n",
      "23         ط            0.00%              0          50.00%             2   \n",
      "24         ه            0.00%              0          80.00%            10   \n",
      "25         خ          100.00%              1           0.00%             0   \n",
      "26         -            0.00%              0          50.00%             2   \n",
      "27         ق           33.33%              3          50.00%             8   \n",
      "28         ض            0.00%              0           0.00%             1   \n",
      "29         ٤            0.00%              0           0.00%             0   \n",
      "30         ٢            0.00%              1           0.00%             0   \n",
      "31         ٨            0.00%              0           0.00%             1   \n",
      "32         ١            0.00%              1           0.00%             0   \n",
      "33         ٧            0.00%              0           0.00%             0   \n",
      "34         ٩            0.00%              0           0.00%             0   \n",
      "35         ٣            0.00%              1           0.00%             0   \n",
      "36   OVERALL           84.21%             95          82.33%           283   \n",
      "\n",
      "   Final_Accuracy  Final_Total Isolated_Accuracy  Isolated_Total  \\\n",
      "0           0.00%            0             0.00%               0   \n",
      "1         100.00%            2             0.00%               0   \n",
      "2         100.00%            1             0.00%               0   \n",
      "3           0.00%            0             0.00%               0   \n",
      "4           0.00%            0             0.00%               0   \n",
      "5         100.00%            2             0.00%               0   \n",
      "6           0.00%            0             0.00%               0   \n",
      "7           0.00%            0             0.00%               0   \n",
      "8          66.67%            3             0.00%               0   \n",
      "9           0.00%            0             0.00%               0   \n",
      "10         50.00%            2             0.00%               0   \n",
      "11          0.00%            0             0.00%               0   \n",
      "12        100.00%            6             0.00%               0   \n",
      "13         92.86%           14             0.00%               0   \n",
      "14         83.33%            6             0.00%               0   \n",
      "15         75.00%            4             0.00%               0   \n",
      "16         66.67%            3             0.00%               0   \n",
      "17        100.00%            1           100.00%               1   \n",
      "18         79.17%           24             0.00%               0   \n",
      "19        100.00%            5             0.00%               0   \n",
      "20          0.00%            0             0.00%               0   \n",
      "21          0.00%            4             0.00%               0   \n",
      "22          0.00%            0             0.00%               2   \n",
      "23        100.00%            1             0.00%               0   \n",
      "24         37.50%            8             0.00%               0   \n",
      "25          0.00%            1             0.00%               0   \n",
      "26          0.00%            3            80.00%               5   \n",
      "27        100.00%            1             0.00%               0   \n",
      "28        100.00%            1             0.00%               0   \n",
      "29          0.00%            1             0.00%               0   \n",
      "30          0.00%            0             0.00%               1   \n",
      "31          0.00%            1             0.00%               0   \n",
      "32          0.00%            0             0.00%               0   \n",
      "33          0.00%            1             0.00%               0   \n",
      "34          0.00%            0             0.00%               1   \n",
      "35          0.00%            0             0.00%               0   \n",
      "36         71.58%           95            50.00%              10   \n",
      "\n",
      "   Overall_Accuracy  Overall_Total  \n",
      "0           100.00%              2  \n",
      "1           100.00%              2  \n",
      "2           100.00%              5  \n",
      "3           100.00%              3  \n",
      "4           100.00%              5  \n",
      "5           100.00%              2  \n",
      "6            95.24%             21  \n",
      "7            94.12%             17  \n",
      "8            91.11%             45  \n",
      "9            88.89%              9  \n",
      "10           86.67%             15  \n",
      "11           84.62%             13  \n",
      "12           84.44%             45  \n",
      "13           83.87%             31  \n",
      "14           83.33%              6  \n",
      "15           82.05%             78  \n",
      "16           81.82%             11  \n",
      "17           81.25%             16  \n",
      "18           80.00%             35  \n",
      "19           80.00%             20  \n",
      "20           75.00%              4  \n",
      "21           72.73%             33  \n",
      "22           66.67%              9  \n",
      "23           66.67%              3  \n",
      "24           61.11%             18  \n",
      "25           50.00%              2  \n",
      "26           50.00%             10  \n",
      "27           50.00%             12  \n",
      "28           50.00%              2  \n",
      "29            0.00%              1  \n",
      "30            0.00%              2  \n",
      "31            0.00%              2  \n",
      "32            0.00%              1  \n",
      "33            0.00%              1  \n",
      "34            0.00%              1  \n",
      "35            0.00%              1  \n",
      "36           79.92%            483  \n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def get_char_form(char, position):\n",
    "    \"\"\"\n",
    "    Determine the Unicode form of an Arabic character based on its position.\n",
    "    position can be: 'isolated', 'initial', 'medial', or 'final'\n",
    "    \"\"\"\n",
    "    # Dictionary mapping base characters to their positional forms\n",
    "    # Format: 'base': (isolated, initial, medial, final)\n",
    "    char_forms = {\n",
    "        'ب': ('\\u0628', '\\uFE91', '\\uFE92', '\\uFE90'),  # beh\n",
    "        'ت': ('\\u062A', '\\uFE97', '\\uFE98', '\\uFE96'),  # teh\n",
    "        'ث': ('\\u062B', '\\uFE9B', '\\uFE9C', '\\uFE9A'),  # theh\n",
    "        'ج': ('\\u062C', '\\uFE9F', '\\uFEA0', '\\uFE9E'),  # jeem\n",
    "        'ح': ('\\u062D', '\\uFEA3', '\\uFEA4', '\\uFEA2'),  # hah\n",
    "        'خ': ('\\u062E', '\\uFEA7', '\\uFEA8', '\\uFEA6'),  # khah\n",
    "        'س': ('\\u0633', '\\uFEB3', '\\uFEB4', '\\uFEB2'),  # seen\n",
    "        'ش': ('\\u0634', '\\uFEB7', '\\uFEB8', '\\uFEB6'),  # sheen\n",
    "        'ص': ('\\u0635', '\\uFEBB', '\\uFEBC', '\\uFEBA'),  # sad\n",
    "        'ض': ('\\u0636', '\\uFEBF', '\\uFEC0', '\\uFEBE'),  # dad\n",
    "        'ط': ('\\u0637', '\\uFEC3', '\\uFEC4', '\\uFEC2'),  # tah\n",
    "        'ظ': ('\\u0638', '\\uFEC7', '\\uFEC8', '\\uFEC6'),  # zah\n",
    "        'ع': ('\\u0639', '\\uFECB', '\\uFECC', '\\uFECA'),  # ain\n",
    "        'غ': ('\\u063A', '\\uFECF', '\\uFED0', '\\uFECE'),  # ghain\n",
    "        'ف': ('\\u0641', '\\uFED3', '\\uFED4', '\\uFED2'),  # feh\n",
    "        'ق': ('\\u0642', '\\uFED7', '\\uFED8', '\\uFED6'),  # qaf\n",
    "        'ك': ('\\u0643', '\\uFEDB', '\\uFEDC', '\\uFEDA'),  # kaf\n",
    "        'ل': ('\\u0644', '\\uFEDF', '\\uFEE0', '\\uFEDE'),  # lam\n",
    "        'م': ('\\u0645', '\\uFEE3', '\\uFEE4', '\\uFEE2'),  # meem\n",
    "        'ن': ('\\u0646', '\\uFEE7', '\\uFEE8', '\\uFEE6'),  # noon\n",
    "        'ه': ('\\u0647', '\\uFEEB', '\\uFEEC', '\\uFEEA'),  # heh\n",
    "        'ي': ('\\u064A', '\\uFEF3', '\\uFEF4', '\\uFEF2'),  # yeh\n",
    "    }\n",
    "    \n",
    "    positions = {'isolated': 0, 'initial': 1, 'medial': 2, 'final': 3}\n",
    "    \n",
    "    if char in char_forms and position in positions:\n",
    "        return char_forms[char][positions[position]]\n",
    "    return char\n",
    "\n",
    "def analyze_word(word):\n",
    "    \"\"\"\n",
    "    Analyze an Arabic word and determine the correct form for each character.\n",
    "    Returns a list of dictionaries containing character analysis.\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    chars = list(word)\n",
    "    \n",
    "    for i, char in enumerate(chars):\n",
    "        # Determine position\n",
    "        if len(chars) == 1:\n",
    "            position = 'isolated'\n",
    "        elif i == 0:\n",
    "            position = 'initial'\n",
    "        elif i == len(chars) - 1:\n",
    "            position = 'final'\n",
    "        else:\n",
    "            position = 'medial'\n",
    "            \n",
    "        correct_form = get_char_form(char, position)\n",
    "        \n",
    "        analysis = {\n",
    "            'original': char,\n",
    "            'position': position,\n",
    "            'correct_form': correct_form,\n",
    "            'unicode_value': f'U+{ord(correct_form):04X}',\n",
    "            'is_connecting': char in 'بتثجحخسشصضطظعغفقكلمنهي'\n",
    "        }\n",
    "        results.append(analysis)\n",
    "    \n",
    "    return results\n",
    "\n",
    "   \n",
    "\n",
    "class ArabicCharacterAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.reset_metrics()\n",
    "        \n",
    "    def reset_metrics(self):\n",
    "        \"\"\"Initialize metrics tracking dictionaries\"\"\"\n",
    "        # Structure: char -> position -> metrics\n",
    "        self.char_position_metrics = defaultdict(lambda: {\n",
    "            'initial': {'correct': 0, 'total': 0},\n",
    "            'medial': {'correct': 0, 'total': 0},\n",
    "            'final': {'correct': 0, 'total': 0},\n",
    "            'isolated': {'correct': 0, 'total': 0},\n",
    "            'overall': {'correct': 0, 'total': 0}\n",
    "        })\n",
    "        \n",
    "        # Structure: position -> metrics\n",
    "        self.position_metrics = {\n",
    "            'initial': {'correct': 0, 'total': 0},\n",
    "            'medial': {'correct': 0, 'total': 0},\n",
    "            'final': {'correct': 0, 'total': 0},\n",
    "            'isolated': {'correct': 0, 'total': 0}\n",
    "        }\n",
    "\n",
    "    def analyze_position(self, char, index, word_length):\n",
    "        \"\"\"Determine character position in word\"\"\"\n",
    "        if word_length == 1:\n",
    "            return 'isolated'\n",
    "        elif index == 0:\n",
    "            return 'initial'\n",
    "        elif index == word_length - 1:\n",
    "            return 'final'\n",
    "        else:\n",
    "            return 'medial'\n",
    "\n",
    "    def evaluate_dataframes(self, gt_df, ocr_df):\n",
    "        \"\"\"Evaluate ground truth against OCR output\"\"\"\n",
    "        self.reset_metrics()\n",
    "        \n",
    "        # Process each column\n",
    "        for col in gt_df.columns:\n",
    "            for gt_sentence, ocr_sentence in zip(gt_df[col], ocr_df[col]):\n",
    "                if pd.isna(gt_sentence) or pd.isna(ocr_sentence):\n",
    "                    continue\n",
    "                    \n",
    "                self.compare_sentences(str(gt_sentence), str(ocr_sentence))\n",
    "        \n",
    "        return self.generate_report()\n",
    "\n",
    "    def compare_sentences(self, gt_sentence, ocr_sentence):\n",
    "        \"\"\"Compare ground truth and OCR output sentences\"\"\"\n",
    "        gt_words = gt_sentence.split()\n",
    "        ocr_words = ocr_sentence.split()\n",
    "        \n",
    "        for gt_word, ocr_word in zip(gt_words, ocr_words):\n",
    "            # Compare characters\n",
    "            for i, gt_char in enumerate(gt_word):\n",
    "                position = self.analyze_position(gt_char, i, len(gt_word))\n",
    "                \n",
    "                # Get corresponding OCR character\n",
    "                ocr_char = ocr_word[i] if i < len(ocr_word) else None\n",
    "                \n",
    "                # Update metrics\n",
    "                self.char_position_metrics[gt_char][position]['total'] += 1\n",
    "                self.char_position_metrics[gt_char]['overall']['total'] += 1\n",
    "                self.position_metrics[position]['total'] += 1\n",
    "                \n",
    "                if ocr_char and gt_char == ocr_char:\n",
    "                    self.char_position_metrics[gt_char][position]['correct'] += 1\n",
    "                    self.char_position_metrics[gt_char]['overall']['correct'] += 1\n",
    "                    self.position_metrics[position]['correct'] += 1\n",
    "\n",
    "    def generate_report(self):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        # Create character position analysis table\n",
    "        char_data = []\n",
    "        \n",
    "        for char, metrics in self.char_position_metrics.items():\n",
    "            row = {\n",
    "                'Character': char,\n",
    "                'Initial_Accuracy': metrics['initial']['correct'] / metrics['initial']['total'] \n",
    "                    if metrics['initial']['total'] > 0 else 0,\n",
    "                'Initial_Total': metrics['initial']['total'],\n",
    "                'Medial_Accuracy': metrics['medial']['correct'] / metrics['medial']['total']\n",
    "                    if metrics['medial']['total'] > 0 else 0,\n",
    "                'Medial_Total': metrics['medial']['total'],\n",
    "                'Final_Accuracy': metrics['final']['correct'] / metrics['final']['total']\n",
    "                    if metrics['final']['total'] > 0 else 0,\n",
    "                'Final_Total': metrics['final']['total'],\n",
    "                'Isolated_Accuracy': metrics['isolated']['correct'] / metrics['isolated']['total']\n",
    "                    if metrics['isolated']['total'] > 0 else 0,\n",
    "                'Isolated_Total': metrics['isolated']['total'],\n",
    "                'Overall_Accuracy': metrics['overall']['correct'] / metrics['overall']['total']\n",
    "                    if metrics['overall']['total'] > 0 else 0,\n",
    "                'Overall_Total': metrics['overall']['total']\n",
    "            }\n",
    "            char_data.append(row)\n",
    "        \n",
    "        # Create position summary row\n",
    "        position_summary = {\n",
    "            'Character': 'OVERALL',\n",
    "            'Initial_Accuracy': self.position_metrics['initial']['correct'] / self.position_metrics['initial']['total']\n",
    "                if self.position_metrics['initial']['total'] > 0 else 0,\n",
    "            'Initial_Total': self.position_metrics['initial']['total'],\n",
    "            'Medial_Accuracy': self.position_metrics['medial']['correct'] / self.position_metrics['medial']['total']\n",
    "                if self.position_metrics['medial']['total'] > 0 else 0,\n",
    "            'Medial_Total': self.position_metrics['medial']['total'],\n",
    "            'Final_Accuracy': self.position_metrics['final']['correct'] / self.position_metrics['final']['total']\n",
    "                if self.position_metrics['final']['total'] > 0 else 0,\n",
    "            'Final_Total': self.position_metrics['final']['total'],\n",
    "            'Isolated_Accuracy': self.position_metrics['isolated']['correct'] / self.position_metrics['isolated']['total']\n",
    "                if self.position_metrics['isolated']['total'] > 0 else 0,\n",
    "            'Isolated_Total': self.position_metrics['isolated']['total'],\n",
    "            'Overall_Accuracy': sum(p['correct'] for p in self.position_metrics.values()) / \n",
    "                              sum(p['total'] for p in self.position_metrics.values()),\n",
    "            'Overall_Total': sum(p['total'] for p in self.position_metrics.values())\n",
    "        }\n",
    "        \n",
    "        # Create DataFrame and sort by overall accuracy\n",
    "        df = pd.DataFrame(char_data)\n",
    "        df = df.sort_values('Overall_Accuracy', ascending=False)\n",
    "        \n",
    "        # Add position summary row at the bottom\n",
    "        df = pd.concat([df, pd.DataFrame([position_summary])], ignore_index=True)\n",
    "        \n",
    "        # Format accuracies as percentages\n",
    "        for col in df.columns:\n",
    "            if 'Accuracy' in col:\n",
    "                df[col] = df[col].apply(lambda x: f\"{x:.2%}\")\n",
    "                \n",
    "        return df\n",
    "\n",
    "def test_analyzer():\n",
    "  \n",
    "    \n",
    "    # Initialize and run analyzer\n",
    "    analyzer = ArabicCharacterAnalyzer()\n",
    "    results = analyzer.evaluate_dataframes( df_original_nid_1,df_predicted_nid)\n",
    "    \n",
    "    # Display results\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    pd.set_option('display.max_columns', None)\n",
    "    pd.set_option('display.width', None)\n",
    "    print(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = test_analyzer()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Initial_Accuracy</th>\n",
       "      <th>Initial_Total</th>\n",
       "      <th>Medial_Accuracy</th>\n",
       "      <th>Medial_Total</th>\n",
       "      <th>Final_Accuracy</th>\n",
       "      <th>Final_Total</th>\n",
       "      <th>Isolated_Accuracy</th>\n",
       "      <th>Isolated_Total</th>\n",
       "      <th>Overall_Accuracy</th>\n",
       "      <th>Overall_Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ث</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ى</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ت</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ج</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ص</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ء</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ح</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>94.12%</td>\n",
       "      <td>17</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>95.24%</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>و</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>93.33%</td>\n",
       "      <td>15</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>94.12%</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>م</td>\n",
       "      <td>92.86%</td>\n",
       "      <td>14</td>\n",
       "      <td>92.86%</td>\n",
       "      <td>28</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>91.11%</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ك</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>88.89%</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ب</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>90.91%</td>\n",
       "      <td>11</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>86.67%</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>س</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>77.78%</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>84.62%</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ل</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>82.05%</td>\n",
       "      <td>39</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>84.44%</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ن</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>3</td>\n",
       "      <td>71.43%</td>\n",
       "      <td>14</td>\n",
       "      <td>92.86%</td>\n",
       "      <td>14</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>83.87%</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ة</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>83.33%</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>83.33%</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ا</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>35</td>\n",
       "      <td>84.62%</td>\n",
       "      <td>39</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>82.05%</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ز</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>83.33%</td>\n",
       "      <td>6</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>81.82%</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>ع</td>\n",
       "      <td>90.91%</td>\n",
       "      <td>11</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>3</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>81.25%</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>د</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>90.00%</td>\n",
       "      <td>10</td>\n",
       "      <td>79.17%</td>\n",
       "      <td>24</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>ر</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>73.33%</td>\n",
       "      <td>15</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ف</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>75.00%</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ي</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>82.76%</td>\n",
       "      <td>29</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>72.73%</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ش</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>4</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ط</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>66.67%</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ه</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>10</td>\n",
       "      <td>37.50%</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>61.11%</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>خ</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>3</td>\n",
       "      <td>80.00%</td>\n",
       "      <td>5</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ق</td>\n",
       "      <td>33.33%</td>\n",
       "      <td>3</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>8</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ض</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>100.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>٤</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>٢</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>٨</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>١</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>٧</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>٩</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>٣</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>OVERALL</td>\n",
       "      <td>84.21%</td>\n",
       "      <td>95</td>\n",
       "      <td>82.33%</td>\n",
       "      <td>283</td>\n",
       "      <td>71.58%</td>\n",
       "      <td>95</td>\n",
       "      <td>50.00%</td>\n",
       "      <td>10</td>\n",
       "      <td>79.92%</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Character Initial_Accuracy  Initial_Total Medial_Accuracy  Medial_Total  \\\n",
       "0          ث          100.00%              2           0.00%             0   \n",
       "1          ى            0.00%              0           0.00%             0   \n",
       "2          ت            0.00%              0         100.00%             4   \n",
       "3          ج            0.00%              0         100.00%             3   \n",
       "4          ص          100.00%              1         100.00%             4   \n",
       "5          ء            0.00%              0           0.00%             0   \n",
       "6          ح          100.00%              4          94.12%            17   \n",
       "7          و          100.00%              2          93.33%            15   \n",
       "8          م           92.86%             14          92.86%            28   \n",
       "9          ك          100.00%              1          87.50%             8   \n",
       "10         ب          100.00%              2          90.91%            11   \n",
       "11         س          100.00%              4          77.78%             9   \n",
       "12         ل            0.00%              0          82.05%            39   \n",
       "13         ن          100.00%              3          71.43%            14   \n",
       "14         ة            0.00%              0           0.00%             0   \n",
       "15         ا           80.00%             35          84.62%            39   \n",
       "16         ز          100.00%              2          83.33%             6   \n",
       "17         ع           90.91%             11          33.33%             3   \n",
       "18         د            0.00%              1          90.00%            10   \n",
       "19         ر            0.00%              0          73.33%            15   \n",
       "20         ف          100.00%              2          50.00%             2   \n",
       "21         ي            0.00%              0          82.76%            29   \n",
       "22         ش          100.00%              4          66.67%             3   \n",
       "23         ط            0.00%              0          50.00%             2   \n",
       "24         ه            0.00%              0          80.00%            10   \n",
       "25         خ          100.00%              1           0.00%             0   \n",
       "26         -            0.00%              0          50.00%             2   \n",
       "27         ق           33.33%              3          50.00%             8   \n",
       "28         ض            0.00%              0           0.00%             1   \n",
       "29         ٤            0.00%              0           0.00%             0   \n",
       "30         ٢            0.00%              1           0.00%             0   \n",
       "31         ٨            0.00%              0           0.00%             1   \n",
       "32         ١            0.00%              1           0.00%             0   \n",
       "33         ٧            0.00%              0           0.00%             0   \n",
       "34         ٩            0.00%              0           0.00%             0   \n",
       "35         ٣            0.00%              1           0.00%             0   \n",
       "36   OVERALL           84.21%             95          82.33%           283   \n",
       "\n",
       "   Final_Accuracy  Final_Total Isolated_Accuracy  Isolated_Total  \\\n",
       "0           0.00%            0             0.00%               0   \n",
       "1         100.00%            2             0.00%               0   \n",
       "2         100.00%            1             0.00%               0   \n",
       "3           0.00%            0             0.00%               0   \n",
       "4           0.00%            0             0.00%               0   \n",
       "5         100.00%            2             0.00%               0   \n",
       "6           0.00%            0             0.00%               0   \n",
       "7           0.00%            0             0.00%               0   \n",
       "8          66.67%            3             0.00%               0   \n",
       "9           0.00%            0             0.00%               0   \n",
       "10         50.00%            2             0.00%               0   \n",
       "11          0.00%            0             0.00%               0   \n",
       "12        100.00%            6             0.00%               0   \n",
       "13         92.86%           14             0.00%               0   \n",
       "14         83.33%            6             0.00%               0   \n",
       "15         75.00%            4             0.00%               0   \n",
       "16         66.67%            3             0.00%               0   \n",
       "17        100.00%            1           100.00%               1   \n",
       "18         79.17%           24             0.00%               0   \n",
       "19        100.00%            5             0.00%               0   \n",
       "20          0.00%            0             0.00%               0   \n",
       "21          0.00%            4             0.00%               0   \n",
       "22          0.00%            0             0.00%               2   \n",
       "23        100.00%            1             0.00%               0   \n",
       "24         37.50%            8             0.00%               0   \n",
       "25          0.00%            1             0.00%               0   \n",
       "26          0.00%            3            80.00%               5   \n",
       "27        100.00%            1             0.00%               0   \n",
       "28        100.00%            1             0.00%               0   \n",
       "29          0.00%            1             0.00%               0   \n",
       "30          0.00%            0             0.00%               1   \n",
       "31          0.00%            1             0.00%               0   \n",
       "32          0.00%            0             0.00%               0   \n",
       "33          0.00%            1             0.00%               0   \n",
       "34          0.00%            0             0.00%               1   \n",
       "35          0.00%            0             0.00%               0   \n",
       "36         71.58%           95            50.00%              10   \n",
       "\n",
       "   Overall_Accuracy  Overall_Total  \n",
       "0           100.00%              2  \n",
       "1           100.00%              2  \n",
       "2           100.00%              5  \n",
       "3           100.00%              3  \n",
       "4           100.00%              5  \n",
       "5           100.00%              2  \n",
       "6            95.24%             21  \n",
       "7            94.12%             17  \n",
       "8            91.11%             45  \n",
       "9            88.89%              9  \n",
       "10           86.67%             15  \n",
       "11           84.62%             13  \n",
       "12           84.44%             45  \n",
       "13           83.87%             31  \n",
       "14           83.33%              6  \n",
       "15           82.05%             78  \n",
       "16           81.82%             11  \n",
       "17           81.25%             16  \n",
       "18           80.00%             35  \n",
       "19           80.00%             20  \n",
       "20           75.00%              4  \n",
       "21           72.73%             33  \n",
       "22           66.67%              9  \n",
       "23           66.67%              3  \n",
       "24           61.11%             18  \n",
       "25           50.00%              2  \n",
       "26           50.00%             10  \n",
       "27           50.00%             12  \n",
       "28           50.00%              2  \n",
       "29            0.00%              1  \n",
       "30            0.00%              2  \n",
       "31            0.00%              2  \n",
       "32            0.00%              1  \n",
       "33            0.00%              1  \n",
       "34            0.00%              1  \n",
       "35            0.00%              1  \n",
       "36           79.92%            483  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Overall Accuracy: 0.7991718426501035\n",
      "\n",
      "Column-wise Accuracy:\n",
      "\n",
      "First Name:\n",
      "Character Accuracy: 90.48%\n",
      "Word Accuracy: 90.00%\n",
      "\n",
      "Last Name:\n",
      "Character Accuracy: 76.64%\n",
      "Word Accuracy: 61.29%\n",
      "\n",
      "Address:\n",
      "Character Accuracy: 83.85%\n",
      "Word Accuracy: 58.06%\n",
      "\n",
      "District-Govrnate:\n",
      "Character Accuracy: 77.01%\n",
      "Word Accuracy: 69.70%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class MultiColumnArabicEvaluator:\n",
    "    def __init__(self):\n",
    "        self.reset_metrics()\n",
    "    \n",
    "    def reset_metrics(self):\n",
    "        \"\"\"Reset all metrics for new evaluation\"\"\"\n",
    "        self.char_metrics = defaultdict(lambda: {\n",
    "            'total': 0,\n",
    "            'correct': 0,\n",
    "            'position_errors': defaultdict(int),\n",
    "            'substitution_errors': defaultdict(int)\n",
    "        })\n",
    "        self.position_metrics = defaultdict(lambda: {\n",
    "            'total': 0,\n",
    "            'correct': 0,\n",
    "            'errors': defaultdict(int)\n",
    "        })\n",
    "        self.column_metrics = defaultdict(lambda: {\n",
    "            'total_chars': 0,\n",
    "            'correct_chars': 0,\n",
    "            'char_accuracy': 0,\n",
    "            'total_words': 0,\n",
    "            'correct_words': 0,\n",
    "            'word_accuracy': 0,\n",
    "            'common_errors': defaultdict(int)\n",
    "        })\n",
    "\n",
    "    def analyze_position(self, char, index, word_length):\n",
    "        \"\"\"Determine character position in word\"\"\"\n",
    "        if word_length == 1:\n",
    "            return 'isolated'\n",
    "        elif index == 0:\n",
    "            return 'initial'\n",
    "        elif index == word_length - 1:\n",
    "            return 'final'\n",
    "        else:\n",
    "            return 'medial'\n",
    "\n",
    "    def compare_sentences(self, gt_sentence, ocr_sentence):\n",
    "        \"\"\"Compare ground truth and OCR output sentences\"\"\"\n",
    "        gt_words = gt_sentence.split()\n",
    "        ocr_words = ocr_sentence.split()\n",
    "        \n",
    "        word_results = []\n",
    "        for gt_word, ocr_word in zip(gt_words, ocr_words):\n",
    "            char_comparisons = []\n",
    "            \n",
    "            # Compare characters\n",
    "            for i, gt_char in enumerate(gt_word):\n",
    "                gt_pos = self.analyze_position(gt_char, i, len(gt_word))\n",
    "                \n",
    "                # Find corresponding OCR character\n",
    "                ocr_char = ocr_word[i] if i < len(ocr_word) else None\n",
    "                ocr_pos = self.analyze_position(ocr_char, i, len(ocr_word)) if ocr_char else None\n",
    "                \n",
    "                comparison = {\n",
    "                    'ground_truth': {\n",
    "                        'char': gt_char,\n",
    "                        'position': gt_pos,\n",
    "                    },\n",
    "                    'ocr_output': {\n",
    "                        'char': ocr_char,\n",
    "                        'position': ocr_pos,\n",
    "                    },\n",
    "                    'is_correct': gt_char == ocr_char,\n",
    "                    'position_match': gt_pos == ocr_pos if ocr_char else False\n",
    "                }\n",
    "                char_comparisons.append(comparison)\n",
    "                \n",
    "                # Update metrics\n",
    "                if gt_char:\n",
    "                    self.char_metrics[gt_char]['total'] += 1\n",
    "                    self.position_metrics[gt_pos]['total'] += 1\n",
    "                    \n",
    "                    if ocr_char:\n",
    "                        if gt_char == ocr_char:\n",
    "                            self.char_metrics[gt_char]['correct'] += 1\n",
    "                            if gt_pos == ocr_pos:\n",
    "                                self.position_metrics[gt_pos]['correct'] += 1\n",
    "                            else:\n",
    "                                self.position_metrics[gt_pos]['errors'][ocr_pos] += 1\n",
    "                        else:\n",
    "                            self.char_metrics[gt_char]['substitution_errors'][ocr_char] += 1\n",
    "            \n",
    "            word_results.append({\n",
    "                'ground_truth': gt_word,\n",
    "                'ocr_output': ocr_word,\n",
    "                'char_comparisons': char_comparisons,\n",
    "                'word_correct': gt_word == ocr_word\n",
    "            })\n",
    "            \n",
    "        return word_results\n",
    "\n",
    "    def evaluate_dataframes(self, gt_df, ocr_df):\n",
    "        \"\"\"\n",
    "        Evaluate OCR output against ground truth across multiple columns\n",
    "        \n",
    "        Parameters:\n",
    "        gt_df: DataFrame with ground truth sentences\n",
    "        ocr_df: DataFrame with OCR output sentences\n",
    "        \"\"\"\n",
    "        self.reset_metrics()\n",
    "        column_results = {}\n",
    "        \n",
    "        # Verify both DataFrames have the same shape\n",
    "        if gt_df.shape != ocr_df.shape:\n",
    "            raise ValueError(\"Ground truth and OCR DataFrames must have the same shape\")\n",
    "        \n",
    "        # Process each column\n",
    "        for col in gt_df.columns:\n",
    "            column_results[col] = []\n",
    "            self.column_metrics[col] = {\n",
    "                'total_chars': 0,\n",
    "                'correct_chars': 0,\n",
    "                'total_words': 0,\n",
    "                'correct_words': 0,\n",
    "                'error_types': defaultdict(int)\n",
    "            }\n",
    "            \n",
    "            # Process each row in the column\n",
    "            for gt_sentence, ocr_sentence in zip(gt_df[col], ocr_df[col]):\n",
    "                if pd.isna(gt_sentence) or pd.isna(ocr_sentence):\n",
    "                    continue\n",
    "                    \n",
    "                sentence_comparison = self.compare_sentences(str(gt_sentence), str(ocr_sentence))\n",
    "                column_results[col].append({\n",
    "                    'ground_truth': gt_sentence,\n",
    "                    'ocr_output': ocr_sentence,\n",
    "                    'word_comparisons': sentence_comparison\n",
    "                })\n",
    "                \n",
    "                # Update column metrics\n",
    "                self.update_column_metrics(col, sentence_comparison)\n",
    "        \n",
    "        return self.generate_report(column_results)\n",
    "\n",
    "    def update_column_metrics(self, column, sentence_comparison):\n",
    "        \"\"\"Update metrics for a specific column\"\"\"\n",
    "        for word_comp in sentence_comparison:\n",
    "            self.column_metrics[column]['total_words'] += 1\n",
    "            if word_comp['word_correct']:\n",
    "                self.column_metrics[column]['correct_words'] += 1\n",
    "            \n",
    "            for char_comp in word_comp['char_comparisons']:\n",
    "                self.column_metrics[column]['total_chars'] += 1\n",
    "                if char_comp['is_correct']:\n",
    "                    self.column_metrics[column]['correct_chars'] += 1\n",
    "                else:\n",
    "                    error_type = 'position_error' if char_comp['ocr_output']['char'] else 'substitution_error'\n",
    "                    self.column_metrics[column]['error_types'][error_type] += 1\n",
    "\n",
    "    def generate_report(self, column_results):\n",
    "        \"\"\"Generate comprehensive evaluation report\"\"\"\n",
    "        report = {\n",
    "            'overall_metrics': {},\n",
    "            'column_metrics': {},\n",
    "            'character_metrics': {},\n",
    "            'position_metrics': {},\n",
    "            'detailed_results': column_results\n",
    "        }\n",
    "        \n",
    "        # Calculate overall metrics\n",
    "        total_chars = sum(m['total'] for m in self.char_metrics.values())\n",
    "        correct_chars = sum(m['correct'] for m in self.char_metrics.values())\n",
    "        report['overall_metrics'] = {\n",
    "            'total_characters': total_chars,\n",
    "            'correct_characters': correct_chars,\n",
    "            'character_accuracy': correct_chars / total_chars if total_chars > 0 else 0\n",
    "        }\n",
    "        \n",
    "        # Calculate column-specific metrics\n",
    "        for col, metrics in self.column_metrics.items():\n",
    "            report['column_metrics'][col] = {\n",
    "                'character_accuracy': metrics['correct_chars'] / metrics['total_chars'] if metrics['total_chars'] > 0 else 0,\n",
    "                'word_accuracy': metrics['correct_words'] / metrics['total_words'] if metrics['total_words'] > 0 else 0,\n",
    "                'error_distribution': dict(metrics['error_types'])\n",
    "            }\n",
    "        \n",
    "        # Character-specific metrics\n",
    "        report['character_metrics'] = pd.DataFrame([{\n",
    "            'character': char,\n",
    "            'total_occurrences': metrics['total'],\n",
    "            'correct_recognitions': metrics['correct'],\n",
    "            'accuracy': metrics['correct'] / metrics['total'] if metrics['total'] > 0 else 0,\n",
    "            'position_errors': dict(metrics['position_errors']),\n",
    "            'substitution_errors': dict(metrics['substitution_errors'])\n",
    "        } for char, metrics in self.char_metrics.items()])\n",
    "        \n",
    "        # Position-specific metrics\n",
    "        report['position_metrics'] = pd.DataFrame([{\n",
    "            'position': pos,\n",
    "            'total_occurrences': metrics['total'],\n",
    "            'correct_recognitions': metrics['correct'],\n",
    "            'accuracy': metrics['correct'] / metrics['total'] if metrics['total'] > 0 else 0,\n",
    "            'common_errors': dict(metrics['errors'])\n",
    "        } for pos, metrics in self.position_metrics.items()])\n",
    "        \n",
    "        return report\n",
    "\n",
    "    def visualize_results(self, report, output_dir='./plots'):\n",
    "        \"\"\"Generate visualizations of the results\"\"\"\n",
    "        import os\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # 1. Character Accuracy Heatmap\n",
    "        plt.figure(figsize=(15, 8))\n",
    "        char_accuracies = report['character_metrics'].pivot_table(\n",
    "            values='accuracy',\n",
    "            index='character'\n",
    "        )\n",
    "        sns.heatmap(char_accuracies, annot=True, cmap='YlGnBu', fmt='.2%')\n",
    "        plt.title('Character Recognition Accuracy')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/character_accuracy.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Position Accuracy Bar Plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        pos_data = report['position_metrics']\n",
    "        sns.barplot(x='position', y='accuracy', data=pos_data)\n",
    "        plt.title('Accuracy by Character Position')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/position_accuracy.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Column Performance Comparison\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        col_accuracies = pd.DataFrame(report['column_metrics']).T\n",
    "        col_accuracies[['character_accuracy', 'word_accuracy']].plot(kind='bar')\n",
    "        plt.title('Accuracy by Column')\n",
    "        plt.xlabel('Column')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend(['Character Accuracy', 'Word Accuracy'])\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{output_dir}/column_accuracy.png')\n",
    "        plt.close()\n",
    "\n",
    "def evaluator():\n",
    "\n",
    "    \n",
    "    # Initialize and run evaluator\n",
    "    evaluator = MultiColumnArabicEvaluator()\n",
    "    results = evaluator.evaluate_dataframes( df_original_nid_1, df_predicted_nid)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    evaluator.visualize_results(results)\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    results = evaluator()\n",
    "    \n",
    "    # Print summary results\n",
    "    print(\"\\nOverall Accuracy:\", results['overall_metrics']['character_accuracy'])\n",
    "    print(\"\\nColumn-wise Accuracy:\")\n",
    "    for col, metrics in results['column_metrics'].items():\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"Character Accuracy: {metrics['character_accuracy']:.2%}\")\n",
    "        print(f\"Word Accuracy: {metrics['word_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other way for evaluation using sequence matcher technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "def calculate_accuracy(extracted_text, ground_truth_text):\n",
    "    if pd.isna(extracted_text) and pd.isna(ground_truth_text):\n",
    "        return 1.0\n",
    "    elif pd.isna(extracted_text) or pd.isna(ground_truth_text):\n",
    "        return 0.0\n",
    "    return SequenceMatcher(None, str(extracted_text), str(ground_truth_text)).ratio()\n",
    "\n",
    "def evaluate_ocr_results(extracted_df, ground_truth_df):\n",
    "    if not extracted_df.columns.equals(ground_truth_df.columns):\n",
    "        raise ValueError(\"Columns in extracted_df and ground_truth_df do not match\")\n",
    "    \n",
    "    results = {}\n",
    "    for column in extracted_df.columns:\n",
    "        char_accuracies = []\n",
    "        word_accuracies = []\n",
    "        \n",
    "        for ext, truth in zip(extracted_df[column], ground_truth_df[column]):\n",
    "            char_accuracy = calculate_accuracy(ext, truth)\n",
    "            \n",
    "            # Word-level accuracy\n",
    "            ext_words = str(ext).split() if not pd.isna(ext) else []\n",
    "            truth_words = str(truth).split() if not pd.isna(truth) else []\n",
    "            word_accuracy = calculate_accuracy(' '.join(ext_words), ' '.join(truth_words))\n",
    "            \n",
    "            char_accuracies.append(char_accuracy)\n",
    "            word_accuracies.append(word_accuracy)\n",
    "        \n",
    "        results[column] = {\n",
    "            'char_accuracy': sum(char_accuracies) / len(char_accuracies),\n",
    "            'word_accuracy': sum(word_accuracies) / len(word_accuracies)\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def print_results(results):\n",
    "    print(\"Evaluation Results:\")\n",
    "    for field, accuracies in results.items():\n",
    "        print(f\"\\n{field}:\")\n",
    "        print(f\"  Character-level accuracy: {accuracies['char_accuracy']:.2%}\")\n",
    "        print(f\"  Word-level accuracy: {accuracies['word_accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "\n",
      "First Name:\n",
      "  Character-level accuracy: 98.89%\n",
      "  Word-level accuracy: 98.89%\n",
      "\n",
      "Last Name:\n",
      "  Character-level accuracy: 85.35%\n",
      "  Word-level accuracy: 85.35%\n",
      "\n",
      "Address:\n",
      "  Character-level accuracy: 81.19%\n",
      "  Word-level accuracy: 81.19%\n",
      "\n",
      "District-Govrnate:\n",
      "  Character-level accuracy: 94.89%\n",
      "  Word-level accuracy: 95.83%\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_ocr_results(df_predicted_nid, df_original_nid_1)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Credit Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "inner_df=pd.merge(df_original_credit,df_predicted_credit, on=\"image_name\", how=\"inner\")\n",
    "df_original_credit = inner_df[[col for col in inner_df.columns if '_x' in col] ].rename(columns=lambda x: x.replace('_x', ''))\n",
    "df_predicted_credit = inner_df[[col for col in inner_df.columns if '_y' in col] ].rename(columns=lambda x: x.replace('_y', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "\n",
      "card_number:\n",
      "  Character-level accuracy: 99.88%\n",
      "  Word-level accuracy: 99.88%\n",
      "\n",
      "card_holder:\n",
      "  Character-level accuracy: 95.05%\n",
      "  Word-level accuracy: 95.05%\n",
      "\n",
      "expiry_date:\n",
      "  Character-level accuracy: 98.62%\n",
      "  Word-level accuracy: 98.62%\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_ocr_results(df_predicted_credit, df_original_credit)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results:\n",
      "\n",
      "card_number:\n",
      "  Character-level accuracy: 99.88%\n",
      "  Word-level accuracy: 99.88%\n",
      "\n",
      "card_holder:\n",
      "  Character-level accuracy: 95.05%\n",
      "  Word-level accuracy: 95.05%\n",
      "\n",
      "expiry_date:\n",
      "  Character-level accuracy: 98.62%\n",
      "  Word-level accuracy: 98.62%\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_ocr_results(df_predicted_credit, df_original_credit)\n",
    "print_results(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
